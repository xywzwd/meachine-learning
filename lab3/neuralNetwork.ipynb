{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_train = pd.read_csv('E:/isuclasses/COMS573/lab3/UCI/optdigits.tra.txt', header=None).rename(columns={64: 'class'}).values\n",
    "opt_test = pd.read_csv('E:/isuclasses/COMS573/lab3/UCI/optdigits.tes.txt', header=None).rename(columns={64: 'class'}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[:, :64]/255.0\n",
    "test_x = test[:, :64]/255.0\n",
    "\n",
    "train_y = train[:, 64]\n",
    "test_y = test[:, 64]\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,735\n",
      "Trainable params: 2,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/50\n",
      "3058/3058 [==============================] - 2s 718us/step - loss: 2.2960 - acc: 0.1181 - val_loss: 2.2876 - val_acc: 0.0954\n",
      "Epoch 2/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 2.2570 - acc: 0.1969 - val_loss: 2.1805 - val_acc: 0.2444\n",
      "Epoch 3/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 1.7907 - acc: 0.4055 - val_loss: 1.2303 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.9721 - acc: 0.6504 - val_loss: 0.7761 - val_acc: 0.7503\n",
      "Epoch 5/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.6102 - acc: 0.7855 - val_loss: 0.7285 - val_acc: 0.7268\n",
      "Epoch 6/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.4565 - acc: 0.8519 - val_loss: 0.5925 - val_acc: 0.7817\n",
      "Epoch 7/50\n",
      "3058/3058 [==============================] - 0s 57us/step - loss: 0.4222 - acc: 0.8581 - val_loss: 0.3849 - val_acc: 0.8706\n",
      "Epoch 8/50\n",
      "3058/3058 [==============================] - 0s 60us/step - loss: 0.3399 - acc: 0.8927 - val_loss: 0.3175 - val_acc: 0.9007\n",
      "Epoch 9/50\n",
      "3058/3058 [==============================] - 0s 56us/step - loss: 0.3128 - acc: 0.9061 - val_loss: 0.3297 - val_acc: 0.8967\n",
      "Epoch 10/50\n",
      "3058/3058 [==============================] - 0s 57us/step - loss: 0.2851 - acc: 0.9124 - val_loss: 0.4299 - val_acc: 0.8549\n",
      "Epoch 11/50\n",
      "3058/3058 [==============================] - 0s 61us/step - loss: 0.2741 - acc: 0.9156 - val_loss: 0.3360 - val_acc: 0.9033\n",
      "Epoch 12/50\n",
      "3058/3058 [==============================] - 0s 55us/step - loss: 0.2616 - acc: 0.9189 - val_loss: 0.2500 - val_acc: 0.9294\n",
      "Epoch 13/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.2484 - acc: 0.9238 - val_loss: 0.5346 - val_acc: 0.8392\n",
      "Epoch 14/50\n",
      "3058/3058 [==============================] - 0s 68us/step - loss: 0.2428 - acc: 0.9232 - val_loss: 0.4180 - val_acc: 0.8732\n",
      "Epoch 15/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.2141 - acc: 0.9284 - val_loss: 0.3312 - val_acc: 0.8928\n",
      "Epoch 16/50\n",
      "3058/3058 [==============================] - 0s 50us/step - loss: 0.1992 - acc: 0.9362 - val_loss: 0.4383 - val_acc: 0.8667\n",
      "Epoch 17/50\n",
      "3058/3058 [==============================] - 0s 52us/step - loss: 0.1871 - acc: 0.9428 - val_loss: 0.2133 - val_acc: 0.9373\n",
      "Epoch 18/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1819 - acc: 0.9438 - val_loss: 0.2054 - val_acc: 0.9425\n",
      "Epoch 19/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1860 - acc: 0.9366 - val_loss: 0.2028 - val_acc: 0.9386\n",
      "Epoch 20/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1907 - acc: 0.9392 - val_loss: 0.1810 - val_acc: 0.9516\n",
      "Epoch 21/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.1658 - acc: 0.9474 - val_loss: 0.2406 - val_acc: 0.9255\n",
      "Epoch 22/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.1741 - acc: 0.9444 - val_loss: 0.3291 - val_acc: 0.9020\n",
      "Epoch 23/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1597 - acc: 0.9480 - val_loss: 0.2214 - val_acc: 0.9333\n",
      "Epoch 24/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1571 - acc: 0.9457 - val_loss: 0.2702 - val_acc: 0.9229\n",
      "Epoch 25/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1596 - acc: 0.9509 - val_loss: 0.2043 - val_acc: 0.9333\n",
      "Epoch 26/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1420 - acc: 0.9575 - val_loss: 0.1878 - val_acc: 0.9425\n",
      "Epoch 27/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1637 - acc: 0.9464 - val_loss: 0.2698 - val_acc: 0.9216\n",
      "Epoch 28/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1334 - acc: 0.9581 - val_loss: 0.2324 - val_acc: 0.9359\n",
      "Epoch 29/50\n",
      "3058/3058 [==============================] - 0s 55us/step - loss: 0.1538 - acc: 0.9526 - val_loss: 0.2322 - val_acc: 0.9373\n",
      "Epoch 30/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1468 - acc: 0.9539 - val_loss: 0.2084 - val_acc: 0.9451\n",
      "Epoch 31/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1565 - acc: 0.9506 - val_loss: 0.3670 - val_acc: 0.8863\n",
      "Epoch 32/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1452 - acc: 0.9536 - val_loss: 0.2348 - val_acc: 0.9229\n",
      "Epoch 33/50\n",
      "3058/3058 [==============================] - 0s 52us/step - loss: 0.1272 - acc: 0.9621 - val_loss: 0.4159 - val_acc: 0.8902\n",
      "Epoch 34/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1528 - acc: 0.9480 - val_loss: 0.1832 - val_acc: 0.9451\n",
      "Epoch 35/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1360 - acc: 0.9539 - val_loss: 0.2508 - val_acc: 0.9229\n",
      "Epoch 36/50\n",
      "3058/3058 [==============================] - 0s 55us/step - loss: 0.1293 - acc: 0.9581 - val_loss: 0.2552 - val_acc: 0.9268\n",
      "Epoch 37/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.1284 - acc: 0.9578 - val_loss: 0.1343 - val_acc: 0.9634\n",
      "Epoch 38/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1339 - acc: 0.9565 - val_loss: 0.2508 - val_acc: 0.9333\n",
      "Epoch 39/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.1167 - acc: 0.9608 - val_loss: 0.1990 - val_acc: 0.9412\n",
      "Epoch 40/50\n",
      "3058/3058 [==============================] - 0s 56us/step - loss: 0.1272 - acc: 0.9604 - val_loss: 0.2020 - val_acc: 0.9503\n",
      "Epoch 41/50\n",
      "3058/3058 [==============================] - 0s 55us/step - loss: 0.1192 - acc: 0.9601 - val_loss: 0.1929 - val_acc: 0.9490\n",
      "Epoch 42/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.1244 - acc: 0.9568 - val_loss: 0.1772 - val_acc: 0.9477\n",
      "Epoch 43/50\n",
      "3058/3058 [==============================] - 0s 54us/step - loss: 0.0993 - acc: 0.9702 - val_loss: 0.3162 - val_acc: 0.9137\n",
      "Epoch 44/50\n",
      "3058/3058 [==============================] - 0s 55us/step - loss: 0.1014 - acc: 0.9666 - val_loss: 0.2075 - val_acc: 0.9359\n",
      "Epoch 45/50\n",
      "3058/3058 [==============================] - 0s 51us/step - loss: 0.1156 - acc: 0.9611 - val_loss: 0.1375 - val_acc: 0.9608\n",
      "Epoch 46/50\n",
      "3058/3058 [==============================] - 0s 52us/step - loss: 0.0923 - acc: 0.9686 - val_loss: 0.1617 - val_acc: 0.9595\n",
      "Epoch 47/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1183 - acc: 0.9598 - val_loss: 0.1486 - val_acc: 0.9556\n",
      "Epoch 48/50\n",
      "3058/3058 [==============================] - 0s 53us/step - loss: 0.1075 - acc: 0.9673 - val_loss: 0.1792 - val_acc: 0.9438\n",
      "Epoch 49/50\n",
      "3058/3058 [==============================] - 0s 52us/step - loss: 0.1123 - acc: 0.9595 - val_loss: 0.1554 - val_acc: 0.9542\n",
      "Epoch 50/50\n",
      "3058/3058 [==============================] - 0s 52us/step - loss: 0.1079 - acc: 0.9621 - val_loss: 0.1696 - val_acc: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[364   0   2   0   1   4   0   0   1   4]\n",
      " [  0 368   0   3   1   0   0   0  11   6]\n",
      " [  1   3 363   9   0   0   0   0   4   0]\n",
      " [  0   1   0 379   0   4   0   0   0   5]\n",
      " [  1   2   0   0 372   0   3   0   1   8]\n",
      " [  0   0   0   1   0 370   0   0   0   5]\n",
      " [  3   5   1   0   1   0 363   0   4   0]\n",
      " [  0   0   0   5   0   3   0 364   0  15]\n",
      " [  0   1   2   1   0   1   0   0 369   6]\n",
      " [  0   0   0   7   1   1   0   0   0 373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       376\n",
      "           1       0.97      0.95      0.96       389\n",
      "           2       0.99      0.96      0.97       380\n",
      "           3       0.94      0.97      0.95       389\n",
      "           4       0.99      0.96      0.98       387\n",
      "           5       0.97      0.98      0.97       376\n",
      "           6       0.99      0.96      0.98       377\n",
      "           7       1.00      0.94      0.97       387\n",
      "           8       0.95      0.97      0.96       380\n",
      "           9       0.88      0.98      0.93       382\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3823\n",
      "   macro avg       0.97      0.96      0.96      3823\n",
      "weighted avg       0.97      0.96      0.96      3823\n",
      "\n",
      "1797/1797 [==============================] - 0s 30us/step\n",
      "test loss: 0.3124409758623323\n",
      "test accuracy: 0.9232053422370617\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, input_dim = 64),\n",
    "    Activation('relu'),\n",
    "    Dense(50),\n",
    "    Activation('relu'),\n",
    "    Dense(25),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(\n",
    "    optimizer = sgd,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_x, train_y, epochs = 50, validation_split=0.2)\n",
    "prediction = model.predict_classes(train_x)\n",
    "cm = confusion_matrix(train_y.argmax(axis=1), prediction)\n",
    "print(cm)\n",
    "print(classification_report(train_y.argmax(axis=1), prediction))\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "print('test loss:', loss)\n",
    "print('test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('E:/isuclasses/COMS573/lab3/UCI/optdigits.tra.txt', header=None).rename(columns={64: 'class'}).values\n",
    "test = pd.read_csv('E:/isuclasses/COMS573/lab3/UCI/optdigits.tes.txt', header=None).rename(columns={64: 'class'}).values\n",
    "\n",
    "train_x = train[:, :64].reshape(train.shape[0], 8, 8, 1)/255.0\n",
    "test_x = test[:, :64].reshape(test.shape[0], 8, 8, 1)/255.0\n",
    "\n",
    "train_y = train[:, 64]\n",
    "test_y = test[:, 64]\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/50\n",
      "3058/3058 [==============================] - 4s 1ms/step - loss: 2.2946 - acc: 0.2767 - val_loss: 2.2836 - val_acc: 0.5425\n",
      "Epoch 2/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 2.2617 - acc: 0.4235 - val_loss: 2.2305 - val_acc: 0.5438\n",
      "Epoch 3/50\n",
      "3058/3058 [==============================] - 1s 372us/step - loss: 2.1748 - acc: 0.4372 - val_loss: 2.0970 - val_acc: 0.5595\n",
      "Epoch 4/50\n",
      "3058/3058 [==============================] - 1s 388us/step - loss: 1.9896 - acc: 0.4892 - val_loss: 1.8486 - val_acc: 0.5686\n",
      "Epoch 5/50\n",
      "3058/3058 [==============================] - 1s 375us/step - loss: 1.7217 - acc: 0.5585 - val_loss: 1.5392 - val_acc: 0.7176\n",
      "Epoch 6/50\n",
      "3058/3058 [==============================] - 1s 378us/step - loss: 1.4601 - acc: 0.5988 - val_loss: 1.2589 - val_acc: 0.7804\n",
      "Epoch 7/50\n",
      "3058/3058 [==============================] - 1s 375us/step - loss: 1.2428 - acc: 0.6504 - val_loss: 1.0507 - val_acc: 0.7804\n",
      "Epoch 8/50\n",
      "3058/3058 [==============================] - 1s 374us/step - loss: 1.0786 - acc: 0.6965 - val_loss: 0.8785 - val_acc: 0.8431\n",
      "Epoch 9/50\n",
      "3058/3058 [==============================] - 1s 379us/step - loss: 0.9620 - acc: 0.7152 - val_loss: 0.7587 - val_acc: 0.8510\n",
      "Epoch 10/50\n",
      "3058/3058 [==============================] - 1s 375us/step - loss: 0.8564 - acc: 0.7456 - val_loss: 0.6630 - val_acc: 0.8667\n",
      "Epoch 11/50\n",
      "3058/3058 [==============================] - 1s 391us/step - loss: 0.7706 - acc: 0.7731 - val_loss: 0.5922 - val_acc: 0.8719\n",
      "Epoch 12/50\n",
      "3058/3058 [==============================] - 1s 380us/step - loss: 0.7281 - acc: 0.7878 - val_loss: 0.5351 - val_acc: 0.8863\n",
      "Epoch 13/50\n",
      "3058/3058 [==============================] - 1s 378us/step - loss: 0.6642 - acc: 0.8015 - val_loss: 0.4977 - val_acc: 0.8980\n",
      "Epoch 14/50\n",
      "3058/3058 [==============================] - 1s 384us/step - loss: 0.6243 - acc: 0.8179 - val_loss: 0.4569 - val_acc: 0.8928\n",
      "Epoch 15/50\n",
      "3058/3058 [==============================] - 1s 380us/step - loss: 0.5839 - acc: 0.8234 - val_loss: 0.4203 - val_acc: 0.8993\n",
      "Epoch 16/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.5402 - acc: 0.8398 - val_loss: 0.3896 - val_acc: 0.9046\n",
      "Epoch 17/50\n",
      "3058/3058 [==============================] - 1s 379us/step - loss: 0.5096 - acc: 0.8434 - val_loss: 0.3721 - val_acc: 0.9020\n",
      "Epoch 18/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.4980 - acc: 0.8476 - val_loss: 0.3518 - val_acc: 0.9229\n",
      "Epoch 19/50\n",
      "3058/3058 [==============================] - 1s 393us/step - loss: 0.4612 - acc: 0.8685 - val_loss: 0.3326 - val_acc: 0.9124\n",
      "Epoch 20/50\n",
      "3058/3058 [==============================] - 1s 383us/step - loss: 0.4486 - acc: 0.8666 - val_loss: 0.3189 - val_acc: 0.9229\n",
      "Epoch 21/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.4198 - acc: 0.8731 - val_loss: 0.2946 - val_acc: 0.9346\n",
      "Epoch 22/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.4218 - acc: 0.8777 - val_loss: 0.2876 - val_acc: 0.9320\n",
      "Epoch 23/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.3942 - acc: 0.8770 - val_loss: 0.2723 - val_acc: 0.9359\n",
      "Epoch 24/50\n",
      "3058/3058 [==============================] - 1s 378us/step - loss: 0.3776 - acc: 0.8901 - val_loss: 0.2648 - val_acc: 0.9386\n",
      "Epoch 25/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.3704 - acc: 0.8882 - val_loss: 0.2586 - val_acc: 0.9399\n",
      "Epoch 26/50\n",
      "3058/3058 [==============================] - 1s 411us/step - loss: 0.3545 - acc: 0.8986 - val_loss: 0.2413 - val_acc: 0.9451\n",
      "Epoch 27/50\n",
      "3058/3058 [==============================] - 1s 378us/step - loss: 0.3501 - acc: 0.8973 - val_loss: 0.2404 - val_acc: 0.9412\n",
      "Epoch 28/50\n",
      "3058/3058 [==============================] - 1s 394us/step - loss: 0.3295 - acc: 0.9075 - val_loss: 0.2330 - val_acc: 0.9425\n",
      "Epoch 29/50\n",
      "3058/3058 [==============================] - 1s 379us/step - loss: 0.3181 - acc: 0.9091 - val_loss: 0.2203 - val_acc: 0.9503\n",
      "Epoch 30/50\n",
      "3058/3058 [==============================] - 1s 378us/step - loss: 0.3188 - acc: 0.9088 - val_loss: 0.2195 - val_acc: 0.9438\n",
      "Epoch 31/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.3109 - acc: 0.9065 - val_loss: 0.2084 - val_acc: 0.9529\n",
      "Epoch 32/50\n",
      "3058/3058 [==============================] - 1s 386us/step - loss: 0.2968 - acc: 0.9150 - val_loss: 0.2071 - val_acc: 0.9464\n",
      "Epoch 33/50\n",
      "3058/3058 [==============================] - 1s 386us/step - loss: 0.2985 - acc: 0.9088 - val_loss: 0.2043 - val_acc: 0.9516\n",
      "Epoch 34/50\n",
      "3058/3058 [==============================] - 1s 380us/step - loss: 0.2813 - acc: 0.9166 - val_loss: 0.1954 - val_acc: 0.9503\n",
      "Epoch 35/50\n",
      "3058/3058 [==============================] - 1s 389us/step - loss: 0.2735 - acc: 0.9199 - val_loss: 0.1896 - val_acc: 0.9556\n",
      "Epoch 36/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.2780 - acc: 0.9163 - val_loss: 0.1929 - val_acc: 0.9503\n",
      "Epoch 37/50\n",
      "3058/3058 [==============================] - 1s 397us/step - loss: 0.2502 - acc: 0.9287 - val_loss: 0.1787 - val_acc: 0.9556\n",
      "Epoch 38/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.2525 - acc: 0.9297 - val_loss: 0.1772 - val_acc: 0.9542\n",
      "Epoch 39/50\n",
      "3058/3058 [==============================] - 1s 380us/step - loss: 0.2537 - acc: 0.9310 - val_loss: 0.1783 - val_acc: 0.9556\n",
      "Epoch 40/50\n",
      "3058/3058 [==============================] - 1s 383us/step - loss: 0.2403 - acc: 0.9323 - val_loss: 0.1664 - val_acc: 0.9595\n",
      "Epoch 41/50\n",
      "3058/3058 [==============================] - 1s 397us/step - loss: 0.2503 - acc: 0.9274 - val_loss: 0.1698 - val_acc: 0.9542\n",
      "Epoch 42/50\n",
      "3058/3058 [==============================] - 1s 392us/step - loss: 0.2332 - acc: 0.9379 - val_loss: 0.1630 - val_acc: 0.9542\n",
      "Epoch 43/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.2321 - acc: 0.9359 - val_loss: 0.1613 - val_acc: 0.9556\n",
      "Epoch 44/50\n",
      "3058/3058 [==============================] - 1s 388us/step - loss: 0.2220 - acc: 0.9323 - val_loss: 0.1625 - val_acc: 0.9556\n",
      "Epoch 45/50\n",
      "3058/3058 [==============================] - 1s 388us/step - loss: 0.2256 - acc: 0.9395 - val_loss: 0.1569 - val_acc: 0.9556\n",
      "Epoch 46/50\n",
      "3058/3058 [==============================] - 1s 381us/step - loss: 0.2186 - acc: 0.9333 - val_loss: 0.1573 - val_acc: 0.9490\n",
      "Epoch 47/50\n",
      "3058/3058 [==============================] - 1s 390us/step - loss: 0.2121 - acc: 0.9402 - val_loss: 0.1467 - val_acc: 0.9634\n",
      "Epoch 48/50\n",
      "3058/3058 [==============================] - 1s 399us/step - loss: 0.1968 - acc: 0.9408 - val_loss: 0.1488 - val_acc: 0.9556\n",
      "Epoch 49/50\n",
      "3058/3058 [==============================] - 1s 385us/step - loss: 0.2015 - acc: 0.9411 - val_loss: 0.1483 - val_acc: 0.9569\n",
      "Epoch 50/50\n",
      "3058/3058 [==============================] - 1s 382us/step - loss: 0.2028 - acc: 0.9398 - val_loss: 0.1412 - val_acc: 0.9582\n",
      "[[371   0   0   0   4   0   1   0   0   0]\n",
      " [  0 373   2   0   0   0   0   2   8   4]\n",
      " [  0   3 370   2   0   1   1   2   1   0]\n",
      " [  0   0   2 378   0   5   0   0   2   2]\n",
      " [  0   0   0   0 372   0   9   0   1   5]\n",
      " [  0   0   1   2   0 367   0   0   1   5]\n",
      " [  0   2   0   0   1   0 374   0   0   0]\n",
      " [  0   1   0   1   1   0   0 379   1   4]\n",
      " [  0  18   4   3   1   2   0   1 350   1]\n",
      " [  0   2   0  10   3   1   0   5   2 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       376\n",
      "           1       0.93      0.96      0.95       389\n",
      "           2       0.98      0.97      0.97       380\n",
      "           3       0.95      0.97      0.96       389\n",
      "           4       0.97      0.96      0.97       387\n",
      "           5       0.98      0.98      0.98       376\n",
      "           6       0.97      0.99      0.98       377\n",
      "           7       0.97      0.98      0.98       387\n",
      "           8       0.96      0.92      0.94       380\n",
      "           9       0.94      0.94      0.94       382\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3823\n",
      "   macro avg       0.97      0.97      0.97      3823\n",
      "weighted avg       0.97      0.97      0.97      3823\n",
      "\n",
      "1797/1797 [==============================] - 1s 299us/step\n",
      "test loss: 0.2011559256660852\n",
      "test accuracy: 0.9387868670337255\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution2D(\n",
    "    input_shape = (8, 8, 1),\n",
    "    filters = 32,\n",
    "    kernel_size = 7,\n",
    "    strides = 1,\n",
    "    padding = 'same',\n",
    "    activation= 'relu' \n",
    "))\n",
    "model1.add(MaxPooling2D(\n",
    "    pool_size=2,\n",
    "    strides = 2,\n",
    "    padding = 'same'\n",
    "))\n",
    "\n",
    "model1.add(Convolution2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 7,\n",
    "    strides = 1,\n",
    "    padding = 'same',\n",
    "    activation= 'relu'\n",
    "))\n",
    "model1.add(MaxPooling2D(2, 2, 'same'))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation= 'relu' ))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(10, activation= 'softmax' ))\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model1.compile(loss= 'categorical_crossentropy' , optimizer= adam , metrics=[ 'accuracy' ])\n",
    "model1.fit(train_x, train_y, epochs = 50, validation_split=0.2)\n",
    "\n",
    "prediction1 = model1.predict_classes(train_x)\n",
    "cm1 = confusion_matrix(train_y.argmax(axis=1), prediction1)\n",
    "print(cm1)\n",
    "print(classification_report(train_y.argmax(axis=1), prediction1))\n",
    "\n",
    "loss, accuracy = model1.evaluate(test_x, test_y)\n",
    "print('test loss:', loss)\n",
    "print('test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
